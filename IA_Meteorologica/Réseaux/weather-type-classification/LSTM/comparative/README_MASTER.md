# ğŸŒ¦ï¸ Sistema de ComparaciÃ³n de Arquitecturas de ClasificaciÃ³n MeteorolÃ³gica

## ğŸ“‹ DescripciÃ³n General

Este sistema compara tres arquitecturas de redes neuronales para clasificaciÃ³n meteorolÃ³gica:

1. **Modelo Ãšnico**: Clasifica directamente 4 tipos de clima (Cloudy, Rainy, Snowy, Sunny)
2. **Arquitectura JerÃ¡rquica**: 3 modelos especializados (1 general + 2 especialistas)
3. **Voting Ensemble**: Combina las predicciones de ambas arquitecturas

## ğŸ—ï¸ Arquitecturas Implementadas

### 1. Modelo Ãšnico (Baseline)
- **Archivo**: Usa modelo preentrenado en `../summary_4/`
- **Accuracy**: ~90.5%
- **Ventajas**: Simple, sin errores de enrutamiento
- **Desventajas**: No aprovecha especializaciÃ³n

### 2. Arquitectura JerÃ¡rquica
- **Modelo General**: Clasifica Cloudy_Sunny vs Rainy_Snowy
- **Especialista A**: Distingue entre Cloudy y Sunny
- **Especialista B**: Distingue entre Rainy y Snowy
- **Accuracy Original**: ~82.6% (problema: especialistas no manejaban muestras fuera de dominio)
- **Accuracy Corregida**: ~91.6% (especialistas reentrenados con clase "Other")

### 3. Voting Ensemble
- **Combina**: Modelo Ãºnico + Arquitectura jerÃ¡rquica
- **Estrategias**: Hard, Soft, Weighted, Weighted Confidence, Cascade
- **Accuracy**: ~91.6-93% (depende de la estrategia)

## ğŸš€ GuÃ­a de Uso RÃ¡pido

### Prerrequisitos
```powershell
# Activar entorno virtual
.\.venv\Scripts\Activate.ps1

# Navegar al directorio
cd comparative
```

### 1. ComparaciÃ³n BÃ¡sica (Modelos Originales)
```powershell
python run_comparison.py
```

### 2. Corregir y Reentrenar Especialistas
```powershell
# Proceso completo: preparar datos, reentrenar, evaluar
.\run_retraining.bat
```

### 3. ComparaciÃ³n con Modelos Corregidos
```powershell
.\run_comparison_corrected.bat
# O directamente:
python run_comparison_updated.py --use-corrected
```

### 4. Evaluar Voting Ensemble
```powershell
.\run_ensemble.bat
# Seleccionar:
# - Modelos corregidos: s
# - Estrategia: all (evalÃºa todas)
```

## ğŸ“ Estructura de Archivos

### Scripts Principales
```
comparative/
â”œâ”€â”€ evaluate_architectures.py          # Sistema base de evaluaciÃ³n
â”œâ”€â”€ prepare_corrected_datasets.py      # Prepara datasets con clase "Other"
â”œâ”€â”€ retrain_specialists.py             # Reentrena especialistas
â”œâ”€â”€ evaluate_architectures_corrected.py # EvaluaciÃ³n con modelos corregidos
â”œâ”€â”€ ensemble_voting_architecture.py     # ImplementaciÃ³n del voting ensemble
â””â”€â”€ evaluate_ensemble.py               # EvaluaciÃ³n del ensemble
```

### Scripts de EjecuciÃ³n
```
â”œâ”€â”€ run_comparison.py                  # ComparaciÃ³n bÃ¡sica
â”œâ”€â”€ run_comparison_updated.py          # ComparaciÃ³n con opciones
â”œâ”€â”€ run_comparison_corrected.py        # ComparaciÃ³n con modelos corregidos
â”œâ”€â”€ run_retraining.py                  # Script de reentrenamiento
â”œâ”€â”€ run_retraining.bat                 # Batch para reentrenamiento
â”œâ”€â”€ run_comparison_corrected.bat       # Batch para comparaciÃ³n corregida
â””â”€â”€ run_ensemble.bat                   # Batch para ensemble
```

### DocumentaciÃ³n
```
â”œâ”€â”€ README.md                          # DocumentaciÃ³n original
â”œâ”€â”€ README_SOLUCION.md                 # ExplicaciÃ³n de la correcciÃ³n
â”œâ”€â”€ README_ENSEMBLE.md                 # DocumentaciÃ³n del ensemble
â””â”€â”€ README_MASTER.md                   # Este archivo
```

## ğŸ“Š Resultados Esperados

| Arquitectura | Sin CorrecciÃ³n | Con CorrecciÃ³n |
|--------------|----------------|----------------|
| Modelo Ãšnico | 90.5% | 90.5% |
| JerÃ¡rquica | 82.6% | 91.6% |
| Ensemble | - | 91.6-93% |

## ğŸ”§ SoluciÃ³n del Problema Original

**Problema**: Los especialistas fueron entrenados solo con sus clases especÃ­ficas, fallando cuando el modelo general los enrutaba incorrectamente.

**SoluciÃ³n**: 
1. Reentrenar especialistas con TODAS las clases
2. Mapear clases fuera de dominio a "Other"
3. Usar pesos de clase (1.0 para objetivo, 0.3 para "Other")

## ğŸ“ˆ Flujo de Trabajo Recomendado

1. **EvaluaciÃ³n Inicial**
   ```powershell
   python run_comparison.py
   ```

2. **Si la jerÃ¡rquica underperforma** (< modelo Ãºnico)
   ```powershell
   .\run_retraining.bat
   ```

3. **EvaluaciÃ³n con Modelos Corregidos**
   ```powershell
   python run_comparison_updated.py --use-corrected
   ```

4. **Probar Ensemble para Mejor Performance**
   ```powershell
   python evaluate_ensemble.py --evaluate-all --use-corrected
   ```

## ğŸ“‚ Salidas Generadas

```
outputs/
â”œâ”€â”€ comparison_results/           # ComparaciÃ³n bÃ¡sica
â”œâ”€â”€ comparison_results_corrected/ # ComparaciÃ³n con modelos corregidos
â”œâ”€â”€ retrained_a/                 # Especialista A reentrenado
â”œâ”€â”€ retrained_b/                 # Especialista B reentrenado
â””â”€â”€ ensemble_results/            # Resultados del ensemble
```

## ğŸ¯ Mejores PrÃ¡cticas

1. **Siempre verificar** que los modelos corregidos existen antes de usarlos
2. **Usar ensemble** cuando se necesite mÃ¡xima precisiÃ³n
3. **Estrategia "cascade"** o "weighted_confidence" suelen dar mejores resultados
4. **Documentar** quÃ© modelos se usaron en cada experimento

## âš¡ Comandos RÃ¡pidos

```powershell
# Ver ayuda
python evaluate_ensemble.py --help

# Ensemble con todas las estrategias
python evaluate_ensemble.py --evaluate-all --use-corrected

# ComparaciÃ³n rÃ¡pida
python run_comparison_updated.py --use-corrected

# Solo reentrenar sin evaluar
python retrain_specialists.py
```

## ğŸ› ï¸ SoluciÃ³n de Problemas

1. **ModuleNotFoundError**: Activar entorno virtual
2. **FileNotFoundError**: Ejecutar desde directorio `comparative/`
3. **Modelos no encontrados**: Ejecutar `run_retraining.bat` primero
4. **GPU no disponible**: El sistema funciona en CPU automÃ¡ticamente

## ğŸ“š Para MÃ¡s InformaciÃ³n

- **Detalles de la soluciÃ³n**: Ver `README_SOLUCION.md`
- **Detalles del ensemble**: Ver `README_ENSEMBLE.md`
- **Arquitectura original**: Ver `README.md`