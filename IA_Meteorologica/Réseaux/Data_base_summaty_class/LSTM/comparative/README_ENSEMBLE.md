# üó≥Ô∏è Arquitectura de Voting Ensemble

## üìã Descripci√≥n

Esta arquitectura implementa un **Voting Ensemble** que combina las predicciones de:
1. **Modelo √önico**: Predice directamente las 4 clases meteorol√≥gicas
2. **Arquitectura Jer√°rquica**: Sistema de 3 modelos (1 general + 2 especialistas)

El ensemble utiliza m√∫ltiples estrategias de voting para maximizar el rendimiento combinando las fortalezas de ambas arquitecturas.

## üéØ Estrategias de Voting

### 1. **Hard Voting**
- Cada modelo vota por una clase
- En caso de desacuerdo, gana el modelo con mayor confianza
- R√°pido pero menos sofisticado

### 2. **Soft Voting**
- Promedia las probabilidades de ambos modelos
- Considera la distribuci√≥n completa de probabilidades
- Puede aplicar calibraci√≥n de probabilidades

### 3. **Weighted Voting**
- Promedio ponderado con pesos fijos
- Permite dar m√°s importancia a un modelo sobre otro
- Pesos configurables (por defecto 50%-50%)

### 4. **Weighted Confidence Voting** ‚≠ê
- Pesos din√°micos basados en la confianza de cada predicci√≥n
- Considera meta-caracter√≠sticas (entrop√≠a, margen, acuerdo)
- Se adapta a cada muestra individual

### 5. **Cascade Voting** (Recomendado)
- Estrategia adaptativa que selecciona el m√©todo seg√∫n el contexto:
  - Alta confianza + acuerdo ‚Üí Soft voting
  - Problemas de enrutamiento ‚Üí Mayor peso al modelo √∫nico
  - Alto desacuerdo ‚Üí Weighted confidence voting
  - Caso general ‚Üí Weighted voting est√°ndar

## üöÄ C√≥mo Usar

### Ejecuci√≥n R√°pida (Windows)
```powershell
# Evaluar todas las estrategias con modelos corregidos
.\run_ensemble.bat
# Seleccionar: s (para modelos corregidos)
# Estrategia: all
```

### Ejecuci√≥n con Python
```bash
# Evaluar todas las estrategias (recomendado)
python evaluate_ensemble.py --evaluate-all --use-corrected

# Usar una estrategia espec√≠fica
python evaluate_ensemble.py --strategy cascade --use-corrected

# Con modelos originales
python evaluate_ensemble.py --strategy weighted_confidence
```

### Script R√°pido
```bash
# Eval√∫a todas las estrategias autom√°ticamente
python run_ensemble_quick.py --corrected
```

## üìä Resultados Esperados

### Sin Ensemble:
- Modelo √önico: ~90.5% accuracy
- Arquitectura Jer√°rquica (original): ~82.6% accuracy
- Arquitectura Jer√°rquica (corregida): ~92-93% accuracy

### Con Voting Ensemble:
- **Hard Voting**: ~91-92% accuracy
- **Soft Voting**: ~92-93% accuracy
- **Weighted Voting**: ~92-93% accuracy
- **Weighted Confidence**: ~93-94% accuracy ‚≠ê
- **Cascade**: ~93-94% accuracy ‚≠ê

## üîß Configuraci√≥n Avanzada

### Par√°metros del Ensemble

```python
ensemble_config = EnsembleConfig(
    # Estrategia principal
    voting_strategy='cascade',
    
    # Pesos para weighted voting
    single_model_weight=0.5,
    hierarchical_weight=0.5,
    
    # Umbrales
    confidence_threshold=0.85,  # Para an√°lisis de alta confianza
    disagreement_threshold=0.3,  # Para detectar alto desacuerdo
    
    # Opciones avanzadas
    use_calibration=True,      # Calibrar probabilidades
    use_meta_features=True,    # Usar caracter√≠sticas adicionales
    adaptive_weights=True      # Ajustar pesos din√°micamente
)
```

### Meta-Caracter√≠sticas Utilizadas

1. **Niveles de confianza**: M√°xima probabilidad de cada modelo
2. **Entrop√≠a**: Incertidumbre en las distribuciones
3. **Margen**: Diferencia entre las top 2 clases
4. **Acuerdo**: Si los modelos predicen la misma clase
5. **Divergencia KL**: Diferencia entre distribuciones

## üìà An√°lisis de Resultados

### M√©tricas Generadas

1. **Accuracy Comparativo**
   - Modelo √∫nico vs Jer√°rquico vs Ensemble
   - Mejora porcentual sobre cada modelo

2. **An√°lisis de Acuerdo**
   - Tasa de acuerdo entre modelos
   - Performance cuando acuerdan vs discrepan
   - Manejo de casos dif√≠ciles

3. **An√°lisis de Confianza**
   - Distribuci√≥n de scores de confianza
   - Accuracy en muestras de alta confianza
   - Calibraci√≥n de probabilidades

4. **Comparaci√≥n de Estrategias**
   - Performance de cada estrategia
   - Selecci√≥n autom√°tica de la mejor

## üìÅ Archivos de Salida

```
outputs/ensemble_results/
‚îú‚îÄ‚îÄ ensemble_analysis.png          # An√°lisis visual completo
‚îú‚îÄ‚îÄ ensemble_improvements.png      # Gr√°ficos de mejora
‚îú‚îÄ‚îÄ strategy_comparison.png        # Comparaci√≥n de estrategias
‚îú‚îÄ‚îÄ confusion_matrices_*.png       # Matrices de confusi√≥n
‚îú‚îÄ‚îÄ ensemble_report.txt           # Reporte detallado
‚îú‚îÄ‚îÄ ensemble_config.json          # Configuraci√≥n utilizada
‚îî‚îÄ‚îÄ all_strategies_results.json   # Resultados de todas las estrategias
```

## üí° Recomendaciones

1. **Para Mejores Resultados**:
   - Usar modelos especialistas corregidos (`--use-corrected`)
   - Evaluar todas las estrategias primero (`--evaluate-all`)
   - Usar cascade o weighted_confidence para producci√≥n

2. **Optimizaci√≥n**:
   - Ajustar pesos seg√∫n el dominio espec√≠fico
   - Calibrar umbrales bas√°ndose en datos de validaci√≥n
   - Considerar ensemble de m√°s de 2 arquitecturas

3. **Interpretabilidad**:
   - El reporte incluye an√°lisis de casos de acuerdo/desacuerdo
   - Las visualizaciones muestran d√≥nde el ensemble mejora
   - Los meta-features ayudan a entender las decisiones

## üî¨ Detalles T√©cnicos

### Por Qu√© Funciona el Ensemble

1. **Complementariedad**: Los modelos tienen diferentes fortalezas
   - Modelo √∫nico: Visi√≥n global, sin errores de enrutamiento
   - Jer√°rquico: Especializaci√≥n, mejor en clases espec√≠ficas

2. **Reducci√≥n de Varianza**: Promedia errores aleatorios

3. **Robustez**: Menos sensible a muestras dif√≠ciles

4. **Adaptabilidad**: Las estrategias avanzadas se ajustan por muestra

### Limitaciones

- Requiere m√°s tiempo de inferencia (2x)
- Necesita ambos modelos entrenados
- La mejora depende de la complementariedad de los modelos

## üöÄ Pr√≥ximos Pasos

1. **Stacking**: Entrenar un meta-modelo sobre las predicciones
2. **Boosting**: Entrenar modelos secuencialmente
3. **Multi-nivel**: Ensemble de m√∫ltiples arquitecturas
4. **Optimizaci√≥n Bayesiana**: Encontrar pesos √≥ptimos autom√°ticamente